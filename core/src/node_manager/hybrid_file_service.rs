//! Hybridæ–‡ä»¶æœåŠ¡å®ç°
//! 
//! ç»“åˆgRPCæ§åˆ¶å’ŒUTPæ•°æ®ä¼ è¾“çš„é«˜æ€§èƒ½æ–‡ä»¶æœåŠ¡

use std::collections::HashMap;
use std::pin::Pin;
use std::sync::Arc;
use std::net::SocketAddr;
use tokio::sync::Mutex;
use tokio_stream::{wrappers::ReceiverStream, Stream, StreamExt};
use tonic::{Request, Response, Status, Streaming};
use tracing::{debug, error, info, warn};

use crate::proto::file::{
    file_service_server::FileService,
    CreateDirectoryRequest, CreateDirectoryResponse,
    DeleteFileRequest, DeleteFileResponse,
    DownloadFileRequest, DownloadFileResponse,
    FileInfo, FilePermissions, FileType,
    GetFileInfoRequest, GetSyncStatusRequest,
    ListFilesRequest, ListFilesResponse,
    SyncStatus, SyncStatusResponse,
    UploadFileRequest, UploadFileResponse,
};
use crate::vdfs::{VDFS, VDFSConfig, VirtualPath};
use librorum_shared::transport::hybrid::{
    HybridTransferCoordinator, HybridEvent, TransferType, SessionStatus
};

/// Hybridæ–‡ä»¶æœåŠ¡å®ç°
pub struct HybridFileService {
    /// VDFSå®ä¾‹
    vdfs: Option<Arc<VDFS>>,
    /// ä¼ ç»Ÿæ–‡ä»¶å­˜å‚¨ (å‘åå…¼å®¹)
    files: Arc<Mutex<HashMap<String, FileInfo>>>,
    /// æ–‡ä»¶è®¡æ•°å™¨
    file_counter: Arc<Mutex<u64>>,
    /// Hybridä¼ è¾“åè°ƒå™¨
    hybrid_coordinator: Arc<HybridTransferCoordinator>,
    /// UTPæœåŠ¡å™¨é…ç½®
    utp_server_addr: SocketAddr,
    /// æ˜¯å¦å¯ç”¨hybridæ¨¡å¼
    hybrid_enabled: bool,
}

impl HybridFileService {
    /// åˆ›å»ºæ–°çš„Hybridæ–‡ä»¶æœåŠ¡
    pub fn new(utp_server_addr: SocketAddr) -> Self {
        let coordinator = HybridTransferCoordinator::new();
        
        // è®¾ç½®äº‹ä»¶å¤„ç†
        coordinator.add_event_handler(|event| {
            match event {
                HybridEvent::SessionCreated { session_id, transfer_type, file_info } => {
                    info!("ğŸ“ Hybridä¼šè¯åˆ›å»º: {} ({:?}) - {}", 
                        session_id, transfer_type, file_info.name);
                }
                HybridEvent::GrpcCoordinationComplete { session_id, utp_endpoint } => {
                    info!("ğŸ¤ gRPCåè°ƒå®Œæˆ: {} -> UTPç«¯ç‚¹: {}", session_id, utp_endpoint);
                }
                HybridEvent::UtpConnectionEstablished { session_id, transport_mode } => {
                    info!("ğŸ”— UTPè¿æ¥å»ºç«‹: {} (æ¨¡å¼: {:?})", session_id, transport_mode);
                }
                HybridEvent::TransferProgress { session_id, bytes_transferred, total_bytes, transfer_rate } => {
                    let progress = (bytes_transferred as f64 / total_bytes as f64) * 100.0;
                    debug!("ğŸ“Š ä¼ è¾“è¿›åº¦: {} {:.1}% ({:.2} MB/s)", 
                        session_id, progress, transfer_rate / 1024.0 / 1024.0);
                }
                HybridEvent::TransferCompleted { session_id, success, error_message, elapsed_secs } => {
                    if success {
                        info!("âœ… ä¼ è¾“å®Œæˆ: {} (è€—æ—¶: {:.2}s)", session_id, elapsed_secs);
                    } else {
                        error!("âŒ ä¼ è¾“å¤±è´¥: {} - {:?}", session_id, error_message);
                    }
                }
                HybridEvent::SessionStatusChanged { session_id, old_status, new_status } => {
                    debug!("ğŸ”„ ä¼šè¯çŠ¶æ€å˜åŒ–: {} {:?} -> {:?}", session_id, old_status, new_status);
                }
            }
        });
        
        Self {
            vdfs: None,
            files: Arc::new(Mutex::new(HashMap::new())),
            file_counter: Arc::new(Mutex::new(0)),
            hybrid_coordinator: Arc::new(coordinator),
            utp_server_addr,
            hybrid_enabled: true,
        }
    }
    
    /// åˆå§‹åŒ–VDFS
    pub async fn init_vdfs(&mut self, config: VDFSConfig) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        info!("ğŸ”§ åˆå§‹åŒ–Hybridæ–‡ä»¶æœåŠ¡çš„VDFS...");
        let vdfs = VDFS::new(config).await
            .map_err(|e| format!("Failed to initialize VDFS: {}", e))?;
        self.vdfs = Some(Arc::new(vdfs));
        info!("âœ… VDFSåˆå§‹åŒ–æˆåŠŸ");
        Ok(())
    }
    
    /// å¯åŠ¨UTPæœåŠ¡å™¨
    pub async fn start_utp_server(&self) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        if !self.hybrid_enabled {
            return Ok(());
        }
        
        info!("ğŸš€ å¯åŠ¨UTPæœåŠ¡å™¨: {}", self.utp_server_addr);
        
        // è·å–å¯å˜å¼•ç”¨æ¥å¯åŠ¨æœåŠ¡å™¨
        // æ³¨æ„ï¼šè¿™é‡Œéœ€è¦è§£å†³æ¶æ„é—®é¢˜ï¼Œå› ä¸ºcoordinatoråœ¨Arcä¸­
        // æš‚æ—¶ä½¿ç”¨unsafeæ–¹æ³•æˆ–é‡æ–°è®¾è®¡æ¶æ„
        
        let coordinator = unsafe {
            &mut *(Arc::as_ptr(&self.hybrid_coordinator) as *mut HybridTransferCoordinator)
        };
        
        coordinator.start_utp_server(self.utp_server_addr)
            .map_err(|e| format!("Failed to start UTP server: {}", e))?;
        
        info!("âœ… UTPæœåŠ¡å™¨å¯åŠ¨æˆåŠŸ");
        Ok(())
    }
    
    /// è·å–ä¸‹ä¸€ä¸ªæ–‡ä»¶ID
    async fn next_file_id(&self) -> String {
        let mut counter = self.file_counter.lock().await;
        *counter += 1;
        format!("file_{}", *counter)
    }
    
    /// æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨hybridæ¨¡å¼
    fn should_use_hybrid(&self, file_size: u64) -> bool {
        self.hybrid_enabled && file_size > 1024 * 1024 // å¤§äº1MBçš„æ–‡ä»¶ä½¿ç”¨hybridæ¨¡å¼
    }
    
    /// åˆ›å»ºhybridä¸Šä¼ ä¼šè¯
    async fn create_hybrid_upload_session(
        &self,
        file_id: String,
        user_id: String,
        file_name: String,
        file_size: u64,
    ) -> Result<String, Status> {
        let local_path = format!("/tmp/librorum_upload_{}", file_id);
        let remote_path = format!("/files/{}/{}", user_id, file_name);
        let grpc_endpoint = "hybrid_file_service".to_string();
        
        let session_id = self.hybrid_coordinator
            .initiate_upload(file_id, user_id, local_path, remote_path, grpc_endpoint)
            .map_err(|e| Status::internal(format!("Failed to create upload session: {}", e)))?;
        
        info!("ğŸ“¤ åˆ›å»ºhybridä¸Šä¼ ä¼šè¯: {} (æ–‡ä»¶: {}, å¤§å°: {} bytes)", 
            session_id, file_name, file_size);
        
        Ok(session_id)
    }
    
    /// åˆ›å»ºhybridä¸‹è½½ä¼šè¯
    async fn create_hybrid_download_session(
        &self,
        file_id: String,
        user_id: String,
        file_info: &FileInfo,
    ) -> Result<String, Status> {
        let local_path = format!("/tmp/librorum_download_{}", file_id);
        let remote_path = format!("/files/{}/{}", user_id, file_info.name);
        let grpc_endpoint = "hybrid_file_service".to_string();
        
        let session_id = self.hybrid_coordinator
            .initiate_download(
                file_id, 
                user_id, 
                local_path, 
                remote_path, 
                file_info.size as u64, 
                grpc_endpoint
            )
            .map_err(|e| Status::internal(format!("Failed to create download session: {}", e)))?;
        
        info!("ğŸ“¥ åˆ›å»ºhybridä¸‹è½½ä¼šè¯: {} (æ–‡ä»¶: {}, å¤§å°: {} bytes)", 
            session_id, file_info.name, file_info.size);
        
        Ok(session_id)
    }
    
    /// å¤„ç†ä¼ ç»Ÿä¸Šä¼  (å°æ–‡ä»¶æˆ–ç¦ç”¨hybridæ¨¡å¼)
    async fn handle_traditional_upload(
        &self,
        mut stream: Streaming<UploadFileRequest>,
    ) -> Result<Response<UploadFileResponse>, Status> {
        info!("ğŸ“¤ å¤„ç†ä¼ ç»Ÿä¸Šä¼ ...");
        
        let mut file_info: Option<FileInfo> = None;
        let mut received_chunks = Vec::new();
        let mut total_size = 0u64;
        
        while let Some(request) = stream.next().await {
            let request = request?;
            
            match request.data {
                Some(crate::proto::file::upload_file_request::Data::Metadata(info)) => {
                    info!("ğŸ“‹ æ¥æ”¶æ–‡ä»¶ä¿¡æ¯: {} ({} bytes)", info.name, info.size);
                    file_info = Some(info);
                }
                Some(crate::proto::file::upload_file_request::Data::Chunk(chunk)) => {
                    total_size += chunk.len() as u64;
                    received_chunks.push(chunk);
                    debug!("ğŸ“¦ æ¥æ”¶æ•°æ®å—: {} bytes (æ€»è®¡: {} bytes)", chunk.len(), total_size);
                }
                None => {
                    warn!("æ”¶åˆ°ç©ºçš„ä¸Šä¼ è¯·æ±‚");
                }
            }
        }
        
        let file_info = file_info.ok_or_else(|| Status::invalid_argument("æ²¡æœ‰æ¥æ”¶åˆ°æ–‡ä»¶ä¿¡æ¯"))?;
        
        if total_size != file_info.size as u64 {
            return Err(Status::invalid_argument(format!(
                "æ–‡ä»¶å¤§å°ä¸åŒ¹é…: æœŸæœ› {} bytes, å®é™…æ¥æ”¶ {} bytes",
                file_info.size as u64, total_size
            )));
        }
        
        let file_id = self.next_file_id().await;
        
        // å¦‚æœæœ‰VDFSï¼Œä¿å­˜åˆ°VDFS
        if let Some(vdfs) = &self.vdfs {
            let virtual_path = VirtualPath::new(&format!("/files/{}", file_info.name))?;
            let combined_data: Vec<u8> = received_chunks.into_iter().flatten().collect();
            
            match vdfs.write_file(&virtual_path, &combined_data).await {
                Ok(_) => {
                    info!("âœ… æ–‡ä»¶æˆåŠŸä¿å­˜åˆ°VDFS: {}", file_info.name);
                }
                Err(e) => {
                    error!("âŒ VDFSä¿å­˜å¤±è´¥: {} - å›é€€åˆ°å†…å­˜å­˜å‚¨", e);
                    // å›é€€åˆ°å†…å­˜å­˜å‚¨
                    let mut files = self.files.lock().await;
                    files.insert(file_id.clone(), file_info.clone());
                }
            }
        } else {
            // ä¿å­˜åˆ°å†…å­˜å­˜å‚¨
            let mut files = self.files.lock().await;
            files.insert(file_id.clone(), file_info.clone());
        }
        
        Ok(Response::new(UploadFileResponse {
            file_id,
            success: true,
            message: "æ–‡ä»¶ä¸Šä¼ æˆåŠŸ".to_string(),
            upload_session_id: None, // ä¼ ç»Ÿä¸Šä¼ ä¸ä½¿ç”¨ä¼šè¯ID
        }))
    }
    
    /// å¤„ç†ä¼ ç»Ÿä¸‹è½½ (å°æ–‡ä»¶æˆ–ç¦ç”¨hybridæ¨¡å¼)
    async fn handle_traditional_download(
        &self,
        request: Request<DownloadFileRequest>,
    ) -> Result<Response<<Self as FileService>::DownloadFileStream>, Status> {
        let req = request.into_inner();
        info!("ğŸ“¥ å¤„ç†ä¼ ç»Ÿä¸‹è½½: {}", req.file_id);
        
        // ä»å­˜å‚¨ä¸­è·å–æ–‡ä»¶ä¿¡æ¯
        let file_info = if let Some(vdfs) = &self.vdfs {
            // å°è¯•ä»VDFSè·å–
            let virtual_path = VirtualPath::new(&format!("/files/{}", req.file_id))?;
            match vdfs.get_file_info(&virtual_path).await {
                Ok(vdfs_info) => {
                    // è½¬æ¢VDFSæ–‡ä»¶ä¿¡æ¯ä¸ºgRPC FileInfo
                    FileInfo {
                        name: req.file_id.clone(),
                        size: vdfs_info.size,
                        file_type: FileType::Regular as i32,
                        permissions: Some(FilePermissions {
                            mode: 0o644,
                            owner: "user".to_string(),
                            group: "group".to_string(),
                            readable: true,
                            writable: true,
                            executable: false,
                        }),
                        created_at: vdfs_info.created_at.timestamp() as u64,
                        modified_at: vdfs_info.modified_at.timestamp() as u64,
                        checksum: vdfs_info.hash.clone(),
                        mime_type: "application/octet-stream".to_string(),
                        encryption_info: None,
                        sync_status: SyncStatus::Synced as i32,
                        chunk_count: vdfs_info.chunk_count as u64,
                        chunk_size: vdfs_info.chunk_size,
                        replication_factor: vdfs_info.replication_factor as u32,
                    }
                }
                Err(_) => {
                    // å›é€€åˆ°å†…å­˜å­˜å‚¨
                    let files = self.files.lock().await;
                    files.get(&req.file_id)
                        .ok_or_else(|| Status::not_found(format!("æ–‡ä»¶æœªæ‰¾åˆ°: {}", req.file_id)))?
                        .clone()
                }
            }
        } else {
            // ä»å†…å­˜å­˜å‚¨è·å–
            let files = self.files.lock().await;
            files.get(&req.file_id)
                .ok_or_else(|| Status::not_found(format!("æ–‡ä»¶æœªæ‰¾åˆ°: {}", req.file_id)))?
                .clone()
        };
        
        let (tx, rx) = tokio::sync::mpsc::channel(4);
        
        // å‘é€æ–‡ä»¶ä¿¡æ¯
        let info_response = DownloadFileResponse {
            data: Some(crate::proto::file::download_file_response::Data::FileInfo(file_info.clone())),
        };
        
        if tx.send(Ok(info_response)).await.is_err() {
            return Err(Status::internal("æ— æ³•å‘é€æ–‡ä»¶ä¿¡æ¯"));
        }
        
        // æ¨¡æ‹Ÿæ–‡ä»¶æ•°æ®å‘é€ (å®é™…å®ç°ä¸­ä¼šä»å­˜å‚¨è¯»å–)
        let chunk_size = 8 * 1024 * 1024; // 8MB chunks
        let total_chunks = (file_info.size + chunk_size - 1) / chunk_size;
        
        tokio::spawn(async move {
            for chunk_index in 0..total_chunks {
                let chunk_start = chunk_index * chunk_size;
                let chunk_end = std::cmp::min(chunk_start + chunk_size, file_info.size);
                let chunk_size = chunk_end - chunk_start;
                
                // ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ® (å®é™…å®ç°ä¸­ä¼šä»å­˜å‚¨è¯»å–)
                let chunk_data = vec![0u8; chunk_size as usize];
                
                let chunk_response = DownloadFileResponse {
                    data: Some(crate::proto::file::download_file_response::Data::Chunk(chunk_data)),
                };
                
                if tx.send(Ok(chunk_response)).await.is_err() {
                    break;
                }
                
                debug!("ğŸ“¦ å‘é€æ•°æ®å— {}/{} ({} bytes)", chunk_index + 1, total_chunks, chunk_size);
            }
        });
        
        let output_stream = ReceiverStream::new(rx);
        Ok(Response::new(Box::pin(output_stream) as <Self as FileService>::DownloadFileStream))
    }
}

#[tonic::async_trait]
impl FileService for HybridFileService {
    type DownloadFileStream = Pin<Box<dyn Stream<Item = Result<DownloadFileResponse, Status>> + Send>>;
    
    /// æ–‡ä»¶ä¸Šä¼  - æ”¯æŒhybridæ¨¡å¼
    async fn upload_file(
        &self,
        request: Request<Streaming<UploadFileRequest>>,
    ) -> Result<Response<UploadFileResponse>, Status> {
        let mut stream = request.into_inner();
        
        // å…ˆè¯»å–ç¬¬ä¸€ä¸ªè¯·æ±‚æ¥è·å–æ–‡ä»¶ä¿¡æ¯
        let first_request = stream.next().await
            .ok_or_else(|| Status::invalid_argument("æ²¡æœ‰æ¥æ”¶åˆ°ä¸Šä¼ è¯·æ±‚"))?;
        let first_request = first_request?;
        
        if let Some(crate::proto::file::upload_file_request::Data::FileInfo(file_info)) = &first_request.data {
            // æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨hybridæ¨¡å¼
            if self.should_use_hybrid(file_info.size) {
                info!("ğŸ”€ ä½¿ç”¨hybridæ¨¡å¼ä¸Šä¼ : {} ({} bytes)", file_info.name, file_info.size);
                
                let file_id = self.next_file_id().await;
                let user_id = "default_user".to_string(); // TODO: ä»è®¤è¯ä¿¡æ¯è·å–
                
                let session_id = self.create_hybrid_upload_session(
                    file_id.clone(),
                    user_id,
                    file_info.name.clone(),
                    file_info.size as u64,
                ).await?;
                
                // å¯åŠ¨UTPä¼ è¾“
                let utp_endpoint = format!("{}", self.utp_server_addr);
                self.hybrid_coordinator
                    .start_utp_transfer(&session_id, utp_endpoint)
                    .map_err(|e| Status::internal(format!("Failed to start UTP transfer: {}", e)))?;
                
                return Ok(Response::new(UploadFileResponse {
                    file_id,
                    success: true,
                    message: "Hybridä¸Šä¼ ä¼šè¯å·²åˆ›å»ºï¼Œè¯·ä½¿ç”¨UTPè¿›è¡Œæ•°æ®ä¼ è¾“".to_string(),
                    upload_session_id: Some(session_id),
                }));
            }
        }
        
        // é‡æ–°åˆ›å»ºstreamï¼ŒåŒ…å«ç¬¬ä¸€ä¸ªè¯·æ±‚
        let new_stream = tokio_stream::iter(vec![Ok(first_request)]).chain(stream);
        let streaming = Streaming::new(Box::pin(new_stream));
        
        // ä½¿ç”¨ä¼ ç»Ÿä¸Šä¼ æ–¹å¼
        self.handle_traditional_upload(streaming).await
    }
    
    /// æ–‡ä»¶ä¸‹è½½ - æ”¯æŒhybridæ¨¡å¼
    async fn download_file(
        &self,
        request: Request<DownloadFileRequest>,
    ) -> Result<Response<<Self as FileService>::DownloadFileStream>, Status> {
        let req = request.get_ref();
        info!("ğŸ“¥ ä¸‹è½½æ–‡ä»¶è¯·æ±‚: {}", req.file_id);
        
        // è·å–æ–‡ä»¶ä¿¡æ¯ä»¥æ£€æŸ¥å¤§å°
        let file_info = if let Some(vdfs) = &self.vdfs {
            // ä»VDFSè·å–æ–‡ä»¶ä¿¡æ¯çš„é€»è¾‘
            None // TODO: å®ç°VDFSæ–‡ä»¶ä¿¡æ¯è·å–
        } else {
            let files = self.files.lock().await;
            files.get(&req.file_id).cloned()
        };
        
        if let Some(file_info) = &file_info {
            // æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨hybridæ¨¡å¼
            if self.should_use_hybrid(file_info.size) {
                info!("ğŸ”€ ä½¿ç”¨hybridæ¨¡å¼ä¸‹è½½: {} ({} bytes)", file_info.name, file_info.size);
                
                let user_id = "default_user".to_string(); // TODO: ä»è®¤è¯ä¿¡æ¯è·å–
                
                let session_id = self.create_hybrid_download_session(
                    req.file_id.clone(),
                    user_id,
                    file_info,
                ).await?;
                
                // å¯åŠ¨UTPä¼ è¾“
                let utp_endpoint = format!("{}", self.utp_server_addr);
                self.hybrid_coordinator
                    .start_utp_transfer(&session_id, utp_endpoint)
                    .map_err(|e| Status::internal(format!("Failed to start UTP transfer: {}", e)))?;
                
                // è¿”å›åŒ…å«ä¼šè¯ä¿¡æ¯çš„å“åº”
                let (tx, rx) = tokio::sync::mpsc::channel(1);
                
                let session_info_response = DownloadFileResponse {
                    data: Some(crate::proto::file::download_file_response::Data::FileInfo(
                        FileInfo {
                            name: format!("hybrid_session_{}", session_id),
                            size: 0, // ç‰¹æ®Šæ ‡è®°ï¼Œè¡¨ç¤ºè¿™æ˜¯hybridä¼šè¯ä¿¡æ¯
                            ..file_info.clone()
                        }
                    )),
                };
                
                tokio::spawn(async move {
                    let _ = tx.send(Ok(session_info_response)).await;
                });
                
                let output_stream = ReceiverStream::new(rx);
                return Ok(Response::new(Box::pin(output_stream) as <Self as FileService>::DownloadFileStream));
            }
        }
        
        // ä½¿ç”¨ä¼ ç»Ÿä¸‹è½½æ–¹å¼
        self.handle_traditional_download(request).await
    }
    
    /// åˆ—å‡ºæ–‡ä»¶
    async fn list_files(
        &self,
        request: Request<ListFilesRequest>,
    ) -> Result<Response<ListFilesResponse>, Status> {
        let req = request.into_inner();
        debug!("ğŸ“‹ åˆ—å‡ºæ–‡ä»¶: {}", req.path);
        
        // ä¼˜å…ˆä»VDFSè·å–
        if let Some(vdfs) = &self.vdfs {
            let virtual_path = VirtualPath::new(&req.path)?;
            match vdfs.list_directory(&virtual_path).await {
                Ok(entries) => {
                    let files: Vec<FileInfo> = entries
                        .into_iter()
                        .map(|entry| FileInfo {
                            name: entry.name,
                            size: entry.size,
                            file_type: if entry.is_directory { FileType::Directory } else { FileType::Regular } as i32,
                            permissions: Some(FilePermissions {
                                mode: if entry.is_directory { 0o755 } else { 0o644 },
                                owner: "user".to_string(),
                                group: "group".to_string(),
                                readable: true,
                                writable: true,
                                executable: entry.is_directory,
                            }),
                            created_at: entry.created_at.timestamp() as u64,
                            modified_at: entry.modified_at.timestamp() as u64,
                            hash: entry.hash,
                            mime_type: "application/octet-stream".to_string(),
                            encryption_info: None,
                            sync_status: SyncStatus::Synced as i32,
                            chunk_count: 0,
                            chunk_size: 0,
                            replication_factor: 1,
                        })
                        .collect();
                    
                    return Ok(Response::new(ListFilesResponse { files }));
                }
                Err(e) => {
                    warn!("VDFSåˆ—è¡¨å¤±è´¥ï¼Œå›é€€åˆ°å†…å­˜å­˜å‚¨: {}", e);
                }
            }
        }
        
        // å›é€€åˆ°å†…å­˜å­˜å‚¨
        let files = self.files.lock().await;
        let file_list: Vec<FileInfo> = files.values().cloned().collect();
        
        Ok(Response::new(ListFilesResponse { files: file_list }))
    }
    
    /// åˆ é™¤æ–‡ä»¶
    async fn delete_file(
        &self,
        request: Request<DeleteFileRequest>,
    ) -> Result<Response<DeleteFileResponse>, Status> {
        let req = request.into_inner();
        info!("ğŸ—‘ï¸ åˆ é™¤æ–‡ä»¶: {}", req.file_id);
        
        // ä¼˜å…ˆä»VDFSåˆ é™¤
        if let Some(vdfs) = &self.vdfs {
            let virtual_path = VirtualPath::new(&format!("/files/{}", req.file_id))?;
            match vdfs.delete_file(&virtual_path).await {
                Ok(_) => {
                    return Ok(Response::new(DeleteFileResponse {
                        success: true,
                        message: "æ–‡ä»¶å·²ä»VDFSåˆ é™¤".to_string(),
                    }));
                }
                Err(e) => {
                    warn!("VDFSåˆ é™¤å¤±è´¥ï¼Œå°è¯•å†…å­˜å­˜å‚¨: {}", e);
                }
            }
        }
        
        // ä»å†…å­˜å­˜å‚¨åˆ é™¤
        let mut files = self.files.lock().await;
        if files.remove(&req.file_id).is_some() {
            Ok(Response::new(DeleteFileResponse {
                success: true,
                message: "æ–‡ä»¶å·²åˆ é™¤".to_string(),
            }))
        } else {
            Err(Status::not_found(format!("æ–‡ä»¶æœªæ‰¾åˆ°: {}", req.file_id)))
        }
    }
    
    /// åˆ›å»ºç›®å½•
    async fn create_directory(
        &self,
        request: Request<CreateDirectoryRequest>,
    ) -> Result<Response<CreateDirectoryResponse>, Status> {
        let req = request.into_inner();
        info!("ğŸ“ åˆ›å»ºç›®å½•: {}", req.path);
        
        if let Some(vdfs) = &self.vdfs {
            let virtual_path = VirtualPath::new(&req.path)?;
            match vdfs.create_directory(&virtual_path).await {
                Ok(_) => {
                    return Ok(Response::new(CreateDirectoryResponse {
                        success: true,
                        message: "ç›®å½•å·²åˆ›å»º".to_string(),
                    }));
                }
                Err(e) => {
                    return Err(Status::internal(format!("åˆ›å»ºç›®å½•å¤±è´¥: {}", e)));
                }
            }
        }
        
        // å†…å­˜å­˜å‚¨ä¸æ”¯æŒç›®å½•
        Err(Status::unimplemented("å†…å­˜å­˜å‚¨æ¨¡å¼ä¸æ”¯æŒç›®å½•åˆ›å»º"))
    }
    
    /// è·å–æ–‡ä»¶ä¿¡æ¯
    async fn get_file_info(
        &self,
        request: Request<GetFileInfoRequest>,
    ) -> Result<Response<FileInfo>, Status> {
        let req = request.into_inner();
        debug!("â„¹ï¸ è·å–æ–‡ä»¶ä¿¡æ¯: {}", req.file_id);
        
        // ä¼˜å…ˆä»VDFSè·å–
        if let Some(vdfs) = &self.vdfs {
            let virtual_path = VirtualPath::new(&format!("/files/{}", req.file_id))?;
            if let Ok(vdfs_info) = vdfs.get_file_info(&virtual_path).await {
                let file_info = FileInfo {
                    file_id: req.file_id.clone(),
                    name: req.file_id.clone(),
                    path: format!("/files/{}", req.file_id),
                    parent_path: "/files".to_string(),
                    size: vdfs_info.size as i64,
                    created_at: vdfs_info.created_at.timestamp(),
                    modified_at: vdfs_info.modified_at.timestamp(),
                    accessed_at: chrono::Utc::now().timestamp(),
                    file_type: FileType::Regular as i32,
                    mime_type: "application/octet-stream".to_string(),
                    checksum: vdfs_info.hash.clone(),
                    permissions: Some(FilePermissions {
                        mode: 0o644,
                        owner: "user".to_string(),
                        group: "group".to_string(),
                        readable: true,
                        writable: true,
                        executable: false,
                    }),
                    is_directory: false,
                    is_symlink: false,
                    chunk_count: vdfs_info.chunk_count as i32,
                    chunk_ids: vdfs_info.chunk_ids.clone(),
                    replication_factor: vdfs_info.replication_factor as i32,
                    is_compressed: false,
                    is_encrypted: false,
                    sync_status: SyncStatus::Synced as i32,
                };
                return Ok(Response::new(file_info));
            }
        }
        
        // ä»å†…å­˜å­˜å‚¨è·å–
        let files = self.files.lock().await;
        if let Some(file_info) = files.get(&req.file_id) {
            Ok(Response::new(file_info.clone()))
        } else {
            Err(Status::not_found(format!("æ–‡ä»¶æœªæ‰¾åˆ°: {}", req.file_id)))
        }
    }
    
    /// è·å–åŒæ­¥çŠ¶æ€
    async fn get_sync_status(
        &self,
        request: Request<GetSyncStatusRequest>,
    ) -> Result<Response<SyncStatusResponse>, Status> {
        let req = request.into_inner();
        debug!("ğŸ”„ è·å–åŒæ­¥çŠ¶æ€: {}", req.path);
        
        // è·å–æ‰€æœ‰æ´»è·ƒçš„hybridä¼šè¯
        let active_sessions = self.hybrid_coordinator.get_active_sessions();
        let hybrid_sessions: Vec<_> = active_sessions
            .into_iter()
            .filter(|session| session.file_info.remote_path == req.path)
            .collect();
        
        let sync_status = if hybrid_sessions.is_empty() {
            SyncStatus::Synced
        } else {
            // æ£€æŸ¥ä¼šè¯çŠ¶æ€
            match hybrid_sessions[0].status {
                SessionStatus::Transferring => SyncStatus::Syncing,
                SessionStatus::Failed => SyncStatus::Error,
                _ => SyncStatus::Pending,
            }
        };
        
        Ok(Response::new(SyncStatusResponse {
            overall_status: sync_status as i32,
            pending_uploads: if sync_status == SyncStatus::Pending { 1 } else { 0 },
            pending_downloads: 0,
            syncing_files: if sync_status == SyncStatus::Syncing { 1 } else { 0 },
            error_files: if sync_status == SyncStatus::Error { 1 } else { 0 },
            conflict_files: 0,
            bytes_to_upload: 0,
            bytes_to_download: 0,
            pending_files: vec![],
        }))
    }
}

impl HybridFileService {
    /// è·å–ä¼ è¾“ç»Ÿè®¡ä¿¡æ¯
    pub fn get_transfer_stats(&self) -> TransferStats {
        let sessions = self.hybrid_coordinator.get_active_sessions();
        let total_sessions = sessions.len();
        let active_uploads = sessions.iter().filter(|s| s.transfer_type == TransferType::Upload).count();
        let active_downloads = sessions.iter().filter(|s| s.transfer_type == TransferType::Download).count();
        
        TransferStats {
            total_sessions,
            active_uploads,
            active_downloads,
            total_bytes_transferred: 0, // éœ€è¦ä»ä¼šè¯ä¸­ç´¯è®¡
            average_transfer_rate: 0.0,
        }
    }
}

/// ä¼ è¾“ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct TransferStats {
    pub total_sessions: usize,
    pub active_uploads: usize,
    pub active_downloads: usize,
    pub total_bytes_transferred: u64,
    pub average_transfer_rate: f64,
}

impl Default for HybridFileService {
    fn default() -> Self {
        Self::new("127.0.0.1:9090".parse().unwrap())
    }
}