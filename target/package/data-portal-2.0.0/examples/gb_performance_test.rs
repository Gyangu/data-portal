//! GBçº§é›¶æ‹·è´æ€§èƒ½æµ‹è¯•
//! 
//! æµ‹è¯•çœŸæ­£çš„POSIXå…±äº«å†…å­˜é›¶æ‹·è´æ€§èƒ½

use std::time::Instant;
use std::ptr;
use std::slice;
use std::sync::atomic::{AtomicU64, Ordering};
use std::sync::Arc;
use std::ffi::CString;
use data_portal::SharedMemoryTransport;
use anyhow::Result;

/// é«˜æ€§èƒ½é›¶æ‹·è´æµ‹è¯•
async fn test_zero_copy_gb_performance() -> Result<()> {
    println!("ğŸš€ å¼€å§‹GBçº§POSIXå…±äº«å†…å­˜é›¶æ‹·è´æ€§èƒ½æµ‹è¯•");
    
    // æµ‹è¯•é…ç½®
    let shm_size = 256 * 1024 * 1024; // 256MBå…±äº«å†…å­˜
    let chunk_sizes = vec![
        1024,           // 1KB
        64 * 1024,      // 64KB  
        1024 * 1024,    // 1MB
        16 * 1024 * 1024, // 16MB
    ];
    
    for chunk_size in chunk_sizes {
        println!("\nğŸ“Š æµ‹è¯•æ•°æ®å—å¤§å°: {} KB", chunk_size / 1024);
        
        // åˆ›å»ºå…±äº«å†…å­˜æ®µ
        let shm = SharedMemoryTransport::new("/utp_gb_test", shm_size)?;
        
        // è®¡ç®—èƒ½æ‰§è¡Œå¤šå°‘æ¬¡å®Œæ•´çš„å†™å…¥æ“ä½œ
        let max_operations = (shm_size / chunk_size).min(10000); // æœ€å¤š1ä¸‡æ¬¡æ“ä½œ
        let total_data_gb = (max_operations * chunk_size) as f64 / (1024.0 * 1024.0 * 1024.0);
        
        println!("  æ“ä½œæ¬¡æ•°: {} æ¬¡", max_operations);
        println!("  æ€»æ•°æ®é‡: {:.2} GB", total_data_gb);
        
        // å‡†å¤‡æµ‹è¯•æ•°æ®ï¼ˆé¿å…åœ¨æµ‹è¯•ä¸­åˆ†é…å†…å­˜ï¼‰
        let test_data = vec![0xAAu8; chunk_size];
        let mut read_buffer = vec![0u8; chunk_size];
        
        // === é›¶æ‹·è´å†™å…¥æµ‹è¯• ===
        let start_time = Instant::now();
        
        for i in 0..max_operations {
            let offset = (i * chunk_size) % shm_size;
            if offset + chunk_size <= shm_size {
                unsafe {
                    // é›¶æ‹·è´å†™å…¥ï¼šç›´æ¥å†…å­˜æ‹·è´
                    ptr::copy_nonoverlapping(
                        test_data.as_ptr(),
                        shm.as_ptr().add(offset),
                        chunk_size
                    );
                }
            }
            
            // æ¯1000æ¬¡æ“ä½œè®©å‡ºæ§åˆ¶æƒï¼ˆé¿å…é˜»å¡ï¼‰
            if i % 1000 == 0 && i > 0 {
                tokio::task::yield_now().await;
            }
        }
        
        let write_duration = start_time.elapsed();
        let write_throughput_gb = total_data_gb / write_duration.as_secs_f64();
        let write_ops_per_sec = max_operations as f64 / write_duration.as_secs_f64();
        
        println!("  ğŸ“¤ å†™å…¥æ€§èƒ½:");
        println!("    è€—æ—¶: {:.3} ç§’", write_duration.as_secs_f64());
        println!("    ååé‡: {:.1} GB/s", write_throughput_gb);
        println!("    æ“ä½œé¢‘ç‡: {:.1}K ops/sec", write_ops_per_sec / 1000.0);
        
        // === é›¶æ‹·è´è¯»å–æµ‹è¯• ===
        let start_time = Instant::now();
        
        for i in 0..max_operations {
            let offset = (i * chunk_size) % shm_size;
            if offset + chunk_size <= shm_size {
                unsafe {
                    // é›¶æ‹·è´è¯»å–ï¼šç›´æ¥å†…å­˜æ‹·è´
                    ptr::copy_nonoverlapping(
                        shm.as_ptr().add(offset),
                        read_buffer.as_mut_ptr(),
                        chunk_size
                    );
                }
                
                // ç®€å•éªŒè¯ï¼ˆé¿å…ç¼–è¯‘å™¨ä¼˜åŒ–æ‰è¯»å–æ“ä½œï¼‰
                let _checksum = read_buffer[0].wrapping_add(read_buffer[chunk_size-1]);
            }
            
            if i % 1000 == 0 && i > 0 {
                tokio::task::yield_now().await;
            }
        }
        
        let read_duration = start_time.elapsed();
        let read_throughput_gb = total_data_gb / read_duration.as_secs_f64();
        let read_ops_per_sec = max_operations as f64 / read_duration.as_secs_f64();
        
        println!("  ğŸ“¥ è¯»å–æ€§èƒ½:");
        println!("    è€—æ—¶: {:.3} ç§’", read_duration.as_secs_f64());
        println!("    ååé‡: {:.1} GB/s", read_throughput_gb);
        println!("    æ“ä½œé¢‘ç‡: {:.1}K ops/sec", read_ops_per_sec / 1000.0);
        
        // === åŒå‘ä¼ è¾“æµ‹è¯• ===
        let start_time = Instant::now();
        
        for i in 0..max_operations {
            let offset = (i * chunk_size) % shm_size;
            if offset + chunk_size <= shm_size {
                unsafe {
                    // å†™å…¥
                    ptr::copy_nonoverlapping(
                        test_data.as_ptr(),
                        shm.as_ptr().add(offset),
                        chunk_size
                    );
                    
                    // ç«‹å³è¯»å–éªŒè¯
                    ptr::copy_nonoverlapping(
                        shm.as_ptr().add(offset),
                        read_buffer.as_mut_ptr(),
                        chunk_size
                    );
                }
                
                // éªŒè¯æ•°æ®å®Œæ•´æ€§
                if read_buffer[0] != test_data[0] {
                    println!("âŒ æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥");
                    break;
                }
            }
            
            if i % 1000 == 0 && i > 0 {
                tokio::task::yield_now().await;
            }
        }
        
        let rw_duration = start_time.elapsed();
        let rw_throughput_gb = (total_data_gb * 2.0) / rw_duration.as_secs_f64(); // è¯»å†™åŒå€æ•°æ®
        let rw_ops_per_sec = max_operations as f64 / rw_duration.as_secs_f64();
        
        println!("  ğŸ”„ åŒå‘ä¼ è¾“æ€§èƒ½:");
        println!("    è€—æ—¶: {:.3} ç§’", rw_duration.as_secs_f64());
        println!("    ååé‡: {:.1} GB/s", rw_throughput_gb);
        println!("    æ“ä½œé¢‘ç‡: {:.1}K ops/sec", rw_ops_per_sec / 1000.0);
        
        // è®¡ç®—æ¯å­—èŠ‚å»¶è¿Ÿ
        let latency_ns = (rw_duration.as_nanos() as f64) / (max_operations as f64);
        println!("    å¹³å‡å»¶è¿Ÿ: {:.0} ns/op", latency_ns);
    }
    
    Ok(())
}

/// åŸå§‹å†…å­˜å¸¦å®½åŸºå‡†æµ‹è¯•
async fn test_raw_memory_bandwidth() -> Result<()> {
    println!("\nğŸ”¬ åŸå§‹å†…å­˜å¸¦å®½åŸºå‡†æµ‹è¯•");
    
    let data_size = 1024 * 1024 * 1024; // 1GB
    let source = vec![0xBBu8; data_size];
    let mut dest = vec![0u8; data_size];
    
    println!("æµ‹è¯•æ•°æ®: 1GB");
    
    // æµ‹è¯•memcpyæ€§èƒ½
    let start_time = Instant::now();
    unsafe {
        ptr::copy_nonoverlapping(source.as_ptr(), dest.as_mut_ptr(), data_size);
    }
    let duration = start_time.elapsed();
    
    let throughput_gb = 1.0 / duration.as_secs_f64();
    println!("åŸå§‹memcpyæ€§èƒ½: {:.1} GB/s", throughput_gb);
    
    // éªŒè¯æ•°æ®
    if dest[0] == source[0] && dest[data_size-1] == source[data_size-1] {
        println!("âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡");
    }
    
    Ok(())
}

/// å¹¶å‘é›¶æ‹·è´æµ‹è¯•
async fn test_concurrent_zero_copy() -> Result<()> {
    println!("\nğŸ”€ å¹¶å‘é›¶æ‹·è´æ€§èƒ½æµ‹è¯•");
    
    let shm_size = 512 * 1024 * 1024; // 512MB
    let chunk_size = 1024 * 1024; // 1MBå—
    let concurrent_tasks = 4; // 4ä¸ªå¹¶å‘ä»»åŠ¡
    let operations_per_task = 1000;
    
    let shm = Arc::new(SharedMemoryTransport::new("/utp_concurrent_test", shm_size)?);
    let counter = Arc::new(AtomicU64::new(0));
    
    println!("å¹¶å‘ä»»åŠ¡æ•°: {}", concurrent_tasks);
    println!("æ¯ä»»åŠ¡æ“ä½œæ•°: {}", operations_per_task);
    
    let start_time = Instant::now();
    
    let mut tasks = Vec::new();
    for task_id in 0..concurrent_tasks {
        let shm_clone = shm.clone();
        let counter_clone = counter.clone();
        
        let task = tokio::spawn(async move {
            let test_data = vec![(task_id as u8).wrapping_add(0xCC); chunk_size];
            
            for i in 0..operations_per_task {
                let offset = ((task_id * operations_per_task + i) * chunk_size) % shm_size;
                if offset + chunk_size <= shm_size {
                    unsafe {
                        ptr::copy_nonoverlapping(
                            test_data.as_ptr(),
                            shm_clone.as_ptr().add(offset),
                            chunk_size
                        );
                    }
                    counter_clone.fetch_add(1, Ordering::Relaxed);
                }
                
                if i % 100 == 0 {
                    tokio::task::yield_now().await;
                }
            }
        });
        
        tasks.push(task);
    }
    
    // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    for task in tasks {
        task.await?;
    }
    
    let duration = start_time.elapsed();
    let total_ops = counter.load(Ordering::Relaxed);
    let total_data_gb = (total_ops * chunk_size as u64) as f64 / (1024.0 * 1024.0 * 1024.0);
    let throughput_gb = total_data_gb / duration.as_secs_f64();
    let ops_per_sec = total_ops as f64 / duration.as_secs_f64();
    
    println!("æ€»æ“ä½œæ•°: {}", total_ops);
    println!("æ€»æ•°æ®é‡: {:.2} GB", total_data_gb);
    println!("è€—æ—¶: {:.3} ç§’", duration.as_secs_f64());
    println!("å¹¶å‘ååé‡: {:.1} GB/s", throughput_gb);
    println!("å¹¶å‘æ“ä½œé¢‘ç‡: {:.1}K ops/sec", ops_per_sec / 1000.0);
    
    Ok(())
}

#[tokio::main]
async fn main() -> Result<()> {
    println!("ğŸ¯ Data Portal GBçº§æ€§èƒ½æµ‹è¯•");
    println!("============================================");
    println!("ç›®æ ‡: éªŒè¯POSIXå…±äº«å†…å­˜é›¶æ‹·è´çš„GBçº§æ€§èƒ½");
    println!();
    
    // åŸå§‹å†…å­˜å¸¦å®½åŸºå‡†
    test_raw_memory_bandwidth().await?;
    
    // é›¶æ‹·è´æ€§èƒ½æµ‹è¯•  
    test_zero_copy_gb_performance().await?;
    
    // å¹¶å‘æ€§èƒ½æµ‹è¯•
    test_concurrent_zero_copy().await?;
    
    println!("\nğŸ GBçº§æ€§èƒ½æµ‹è¯•å®Œæˆï¼");
    println!("ğŸ’¡ å¦‚æœæ€§èƒ½ä»ç„¶ä¸ç†æƒ³ï¼Œå¯èƒ½çš„åŸå› ï¼š");
    println!("   - ç³»ç»Ÿå†…å­˜å¸¦å®½é™åˆ¶");
    println!("   - CPUç¼“å­˜æœªå‘½ä¸­");
    println!("   - æ“ä½œç³»ç»Ÿè°ƒåº¦å¼€é”€");
    println!("   - NUMAæ¶æ„å½±å“");
    
    Ok(())
}